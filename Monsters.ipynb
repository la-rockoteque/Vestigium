{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# %% [markdown]\n",
    "# üß∞ Install deps (first run only)"
   ],
   "id": "fabe8f2fed5629a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T10:13:06.296210Z",
     "start_time": "2025-09-11T10:13:06.290343Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b340752660c43a71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# %% [markdown]\n",
    "# üîê Auth & Config"
   ],
   "id": "a86e28276283509f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T10:13:07.476044Z",
     "start_time": "2025-09-11T10:13:06.350468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "# ========= CONFIG =========\n",
    "SERVICE_ACCOUNT_FILE = \"key.json\"   # <-- change\n",
    "SPREADSHEET_ID       = \"1I4FHncl40_xx1Udc_Q2rWWWvpL6xaMlpJyY90WBftag\"            # <-- change\n",
    "WORKSHEET_NAME       = \"Monsters\"                        # <-- change\n",
    "JSON_DIR             = Path(\"data/Monsters\")                 # folder with *.json\n",
    "\n",
    "MATCH_ON       = [\"Name\"]   # use [\"Name\"] if you don't track Source\n",
    "ADD_IF_MISSING = True                 # append new rows if not found\n",
    "DRY_RUN        = False                # True = preview only; no sheet writes\n",
    "# =========================\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "gc = gspread.authorize(creds)\n",
    "\n",
    "ws = gc.open_by_key(SPREADSHEET_ID).worksheet(WORKSHEET_NAME)"
   ],
   "id": "97f1482f930f0681",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# %% [markdown]\n",
    "# üì• Load worksheet as DataFrame & build indices"
   ],
   "id": "fb3062eb5db8675e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T10:13:08.743539Z",
     "start_time": "2025-09-11T10:13:08.481113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "values = ws.get_all_values()  # row 1 = header\n",
    "if not values:\n",
    "  raise RuntimeError(\"Worksheet is empty‚Äîplease add a header row first.\")\n",
    "\n",
    "header = values[0]\n",
    "rows   = values[1:]\n",
    "df     = pd.DataFrame(rows, columns=header)\n",
    "\n",
    "def norm(v: str) -> str:\n",
    "  return (v or \"\").strip()\n",
    "\n",
    "def key_of_row(row: pd.Series) -> Tuple[str, ...]:\n",
    "  return tuple(norm(row.get(k, \"\")) for k in MATCH_ON)\n",
    "\n",
    "row_index = { key_of_row(r): i for i, r in df.iterrows() }  # 0-based DataFrame index\n",
    "\n",
    "# quick helpers\n",
    "def ensure_columns_exist(cols: List[str]) -> None:\n",
    "  \"\"\"Add any missing columns to the header row in the Sheet and our local df.\"\"\"\n",
    "  global header, df\n",
    "  missing = [c for c in cols if c not in header]\n",
    "  if not missing:\n",
    "    return\n",
    "  new_header = header + missing\n",
    "  if not DRY_RUN:\n",
    "    ws.update('1:1', [new_header])  # replace header row\n",
    "  # update local structures\n",
    "  for c in missing:\n",
    "    df[c] = \"\"\n",
    "  header = new_header"
   ],
   "id": "eb7ec0fe030e52bc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# %% [markdown]\n",
    "# üß© JSON schema helpers (matches your Title-Case fields)"
   ],
   "id": "5821bfa4f895ff97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T10:13:08.757457Z",
     "start_time": "2025-09-11T10:13:08.749193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "SPEED_COLS = [\n",
    "  \"Speed (Walking)\",\n",
    "  \"Speed (Swimming)\",\n",
    "  \"Speed (Flying)\",\n",
    "  \"Speed (Burrowing)\",\n",
    "  \"Speed (Climbing)\",\n",
    "]\n",
    "\n",
    "def fmt_hp(hp: Any) -> Tuple[str, str]:\n",
    "  if isinstance(hp, dict):\n",
    "    return (str(hp.get(\"Value\", \"\")), str(hp.get(\"Notes\", \"\")))\n",
    "  return (\"\", \"\")\n",
    "\n",
    "def fmt_ac(ac: Any) -> Tuple[str, str]:\n",
    "  if isinstance(ac, dict):\n",
    "    return (str(ac.get(\"Value\",\"\")), str(ac.get(\"Notes\",\"\")))\n",
    "  if isinstance(ac, (int, float, str)):\n",
    "    return (str(ac), \"\")\n",
    "  return (\"\", \"\")\n",
    "\n",
    "def fmt_speed_list(blip: Any) -> Dict[str, str]:\n",
    "  lst = blip[0].split(\", \")\n",
    "  out = {c: \"\" for c in SPEED_COLS}\n",
    "  if not isinstance(lst, list): return out\n",
    "  for token in map(str, lst):\n",
    "    low = token.lower()\n",
    "    if   \"fly\"   in low: out[\"Speed (Flying)\"]    = token.replace(\"fly \", \"\").split(\" \")[0]\n",
    "    elif \"swim\"  in low: out[\"Speed (Swimming)\"]  = token.replace(\"swim \", \"\").split(\" \")[0]\n",
    "    elif \"burrow\"in low: out[\"Speed (Burrowing)\"] = token.replace(\"burrow \", \"\").split(\" \")[0]\n",
    "    elif \"climb\" in low: out[\"Speed (Climbing)\"]  = token.replace(\"climb \", \"\").split(\" \")[0]\n",
    "    elif \"teleport\" in low: logging.warn(\"teleport is not supported yet.\")\n",
    "    elif \"jump\" in low: logging.warn(\"jump is not supported yet.\")\n",
    "    else:\n",
    "      out[\"Speed (Walking)\"] = token.split(\" \")[0]\n",
    "  return out\n",
    "\n",
    "def fmt_abilities(d: Any) -> Dict[str, str]:\n",
    "  out: Dict[str, str] = {}\n",
    "  if isinstance(d, dict):\n",
    "    for j,c in [(\"Str\",\"STR\"),(\"Dex\",\"DEX\"),(\"Con\",\"CON\"),(\"Int\",\"INT\"),(\"Wis\",\"WIS\"),(\"Cha\",\"CHA\")]:\n",
    "      if j in d:\n",
    "        score = d[j]\n",
    "        out[c] = score\n",
    "        mod_col = f\"{c} Mod\"\n",
    "        if mod_col in header:\n",
    "          try:\n",
    "            mod = (int(score)-10)//2\n",
    "            out[mod_col] = f\"{mod:+d}\"\n",
    "          except Exception:\n",
    "            pass\n",
    "  return out\n",
    "\n",
    "def fmt_bonus_list(lst: Any) -> str:\n",
    "  if not isinstance(lst, list): return \"\"\n",
    "  parts = []\n",
    "  for it in lst:\n",
    "    if isinstance(it, dict):\n",
    "      n = str(it.get(\"Name\",\"\")).strip()\n",
    "      m = it.get(\"Modifier\",\"\")\n",
    "      if n:\n",
    "        parts.append(f\"{n} {m:+d}\" if isinstance(m,int) else f\"{n} {m}\")\n",
    "  return \", \".join(parts)\n",
    "\n",
    "def fmt_list(v: Any) -> str:\n",
    "  return \", \".join(map(str, v)) if isinstance(v, list) else (str(v) if v else \"\")\n",
    "\n",
    "def fmt_blocks(blocks: Any) -> str:\n",
    "  if not isinstance(blocks, list): return \"\"\n",
    "  lines = []\n",
    "  for b in blocks:\n",
    "    if isinstance(b, dict):\n",
    "      nm = str(b.get(\"Name\",\"\")).strip()\n",
    "      ct = str(b.get(\"Content\",\"\")).strip()\n",
    "      if nm and ct: lines.append(f\"{nm}:: {ct}\")\n",
    "      elif ct:      lines.append(ct)\n",
    "      elif nm:      lines.append(nm)\n",
    "  return \";\\n\".join(lines)\n",
    "\n",
    "def monster_to_row_updates(path: Path, m: Dict[str, Any]) -> Dict[str, Any]:\n",
    "  out: Dict[str, Any] = {}\n",
    "\n",
    "  # Identity\n",
    "  name = (m.get(\"Name\") or m.get(\"name\") or path.stem).strip()\n",
    "  out[\"Name\"]   = name\n",
    "  out[\"Source\"] = str(m.get(\"Source\",\"\")).strip()\n",
    "\n",
    "  # Basics\n",
    "  type_text = m.get(\"Type\",\"\").strip()\n",
    "  part_1, alignment = (type_text.split(\", \") + [\"\", \"\"])[:2]\n",
    "  size, creature_type, subtype = (part_1.split(\" \") + [\"\", \"\"])[:3]\n",
    "  \n",
    "  out[\"Type\"] = creature_type\n",
    "  out[\"Size\"] = size\n",
    "  if subtype: out[\"Subtype\"] = subtype\n",
    "  out[\"Alignment\"] = alignment\n",
    "\n",
    "  # AC / HP\n",
    "  ac_val, ac_notes = fmt_ac(m.get(\"AC\"))\n",
    "  if \"Armor Class\" in header and ac_val: out[\"Armor Class\"] = ac_val\n",
    "  if \"Armor Type\"  in header and ac_notes: out[\"Armor Type\"] = ac_notes\n",
    "\n",
    "  hp_val, hd_notes = fmt_hp(m.get(\"HP\"))\n",
    "  hit_dice_parts = hd_notes.split(\" + \")\n",
    "  if \"Hit Points\" in header and hp_val: out[\"Hit Points\"] = hp_val\n",
    "  if \"Hit Dice\"   in header and hd_notes: out[\"Hit Dice\"] = hd_notes[0]\n",
    "\n",
    "  # Speed\n",
    "  out.update({k:v for k,v in fmt_speed_list(m.get(\"Speed\")).items() if k in header and v})\n",
    "\n",
    "  # Abilities\n",
    "  out.update({k:v for k,v in fmt_abilities(m.get(\"Abilities\")).items() if k in header})\n",
    "\n",
    "  # Saves / Skills\n",
    "  saves = fmt_bonus_list(m.get(\"Saves\"))\n",
    "  if \"Saving Throws\" in header and saves: out[\"Saving Throws\"] = saves\n",
    "  elif \"Saves\" in header and saves:       out[\"Saves\"] = saves\n",
    "\n",
    "  skills = fmt_bonus_list(m.get(\"Skills\"))\n",
    "  if \"Skills\" in header and skills: out[\"Skills\"] = skills\n",
    "\n",
    "  # Damage & Conditions\n",
    "  for jkey, col in [\n",
    "    (\"DamageVulnerabilities\", \"Damage Vulnerabilities\"),\n",
    "    (\"DamageResistances\",     \"Damage Resistances\"),\n",
    "    (\"DamageImmunities\",      \"Damage Immunities\"),\n",
    "    (\"ConditionImmunities\",   \"Condition Immunities\"),\n",
    "  ]:\n",
    "    txt = fmt_list(m.get(jkey))\n",
    "    if txt and col in header:\n",
    "      out[col] = txt\n",
    "\n",
    "  # Senses / Languages / Passive\n",
    "  if \"Passive Perception\" in header:\n",
    "    out[\"Passive Perception\"] = int(int(out[\"WIS\"]) / 2 + 10)\n",
    "\n",
    "  # CR / PB\n",
    "  cr = str(m.get(\"Challenge\",\"\")).strip()\n",
    "  if cr and \"CR (Challenge Rating)\" in header:\n",
    "    out[\"CR (Challenge Rating)\"] = cr\n",
    "\n",
    "  pb = str(m.get(\"ProficiencyBonus\", m.get(\"Proficiency\",\"\"))).strip()\n",
    "  if pb and \"Proficiency Bonus\" in header:\n",
    "    out[\"Proficiency Bonus\"] = pb\n",
    "\n",
    "  # Text blocks\n",
    "  blocks = [\n",
    "    (\"Traits\",\"Traits\"), (\"Actions\",\"Actions\"), (\"Reactions\",\"Reactions\"),\n",
    "    (\"BonusActions\",\"Bonus Actions\"), (\"LegendaryAction\",\"Legendary Action\"),\n",
    "    (\"LairAction\",\"Lair Action\"), (\"MythicActions\",\"Mythic Actions\"),\n",
    "  ]\n",
    "  for jkey, col in blocks:\n",
    "    txt = fmt_blocks(m.get(jkey))\n",
    "    if txt and col in header:\n",
    "      out[col] = txt\n",
    "\n",
    "  return out"
   ],
   "id": "daa066ad39610afb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# %% [markdown]\n",
    "# üìÇ Read JSON files, compute updates, and write to Google Sheet"
   ],
   "id": "af5260804e5b2ed1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T10:13:09.648567Z",
     "start_time": "2025-09-11T10:13:08.762261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gspread.utils import rowcol_to_a1\n",
    "# %%\n",
    "def json_files_in_folder(folder: Path) -> List[Path]:\n",
    "  return [p for p in folder.glob(\"*.json\") if p.is_file()]\n",
    "\n",
    "# Ensure we know about all possible columns we might write\n",
    "ensure_columns_exist([\n",
    "  \"Name\",\"Source\",\"Size\",\"Classic 5e Type\",\"Type\",\"New Type\",\"Alignment\",\n",
    "  \"Armor Class\",\"Armor Type\",\"Hit Points\",\"Hit Dice\",\n",
    "  *SPEED_COLS,\n",
    "  \"STR\",\"DEX\",\"CON\",\"INT\",\"WIS\",\"CHA\",\"STR Mod\",\"DEX Mod\",\"CON Mod\",\"INT Mod\",\"WIS Mod\",\"CHA Mod\",\n",
    "  \"Saving Throws\",\"Skills\",\n",
    "  \"Damage Vulnerabilities\",\"Damage Resistances\",\"Damage Immunities\",\"Condition Immunities\",\n",
    "  \"Senses\",\"Languages\",\"Passive Perception\",\n",
    "  \"CR (Challenge Rating)\",\"Proficiency Bonus\",\n",
    "  \"Traits\",\"Actions\",\"Reactions\",\"Bonus Actions\",\"Legendary Action\",\"Lair Action\",\"Mythic Actions\",\n",
    "  \"Description\",\n",
    "])\n",
    "\n",
    "# Prepare updates\n",
    "to_update = 0\n",
    "to_append = 0\n",
    "row_updates_payload = []  # list of {\"range\": \"A5:AZ5\", \"values\": [[...]]}\n",
    "new_rows = []             # list of full row arrays for append_rows\n",
    "\n",
    "# Quick col index map\n",
    "col_index = {name: i for i, name in enumerate(header)}  # 0-based\n",
    "\n",
    "def row_as_full_array(existing: pd.Series, patch: Dict[str, Any]) -> List[str]:\n",
    "  # Merge existing row + patch into a full list aligned to header\n",
    "  vals = [existing.get(h, \"\") for h in header]\n",
    "  for col, v in patch.items():\n",
    "    if col in col_index:\n",
    "      vals[col_index[col]] = str(v)\n",
    "  return [str(v) for v in vals]\n",
    "\n",
    "def empty_row_from_patch(patch: Dict[str, Any]) -> List[str]:\n",
    "  vals = [\"\" for _ in header]\n",
    "  for col, v in patch.items():\n",
    "    if col in col_index:\n",
    "      vals[col_index[col]] = str(v)\n",
    "  return vals\n",
    "\n",
    "# Iterate files\n",
    "for path in json_files_in_folder(JSON_DIR):\n",
    "  try:\n",
    "    m = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "  except Exception as e:\n",
    "    print(f\"Skipped {path.name}: {e}\")\n",
    "    continue\n",
    "\n",
    "  patch = monster_to_row_updates(path, m)\n",
    "  key = tuple(norm(patch.get(k, \"\")) for k in MATCH_ON)\n",
    "\n",
    "  if key in row_index:\n",
    "    # existing row -> compute merged row and send exact row update (A1-based range)\n",
    "    df_idx = row_index[key]\n",
    "    merged = row_as_full_array(df.iloc[df_idx], patch)\n",
    "    # Sheet row number (header is row 1)\n",
    "    sheet_row = df_idx + 2\n",
    "    start_cell = rowcol_to_a1(sheet_row, 1)\n",
    "    end_cell   = rowcol_to_a1(sheet_row, len(header))\n",
    "    rng = f\"{start_cell}:{end_cell}\"\n",
    "    row_updates_payload.append({\"range\": rng, \"values\": [merged]})\n",
    "    to_update += 1\n",
    "    for k, v in patch.items():\n",
    "      df.at[df_idx, k] = v\n",
    "  else:\n",
    "    if ADD_IF_MISSING:\n",
    "      new_rows.append(empty_row_from_patch(patch))\n",
    "      to_append += 1\n",
    "    else:\n",
    "      print(f\"Not found (skipped): {key}\")\n",
    "\n",
    "print(f\"Planned: update {to_update} row(s), append {to_append} row(s).\")\n",
    "\n",
    "if DRY_RUN:\n",
    "  print(\"DRY_RUN=True ‚Äî not writing to Google Sheets.\")\n",
    "else:\n",
    "  # Batch row updates\n",
    "  if row_updates_payload:\n",
    "    ws.batch_update(row_updates_payload, value_input_option=\"USER_ENTERED\")\n",
    "    print(f\"‚úÖ Updated {len(row_updates_payload)} existing row(s).\")\n",
    "  # Append new\n",
    "  if new_rows:\n",
    "    ws.append_rows(new_rows, value_input_option=\"USER_ENTERED\")\n",
    "    print(f\"‚úÖ Appended {len(new_rows)} new row(s).\")\n",
    "  print(\"Done.\")"
   ],
   "id": "9872f4596806f157",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/2knpzhtx0m196v_zk0jw8my80000gn/T/ipykernel_2808/1561739436.py:36: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  elif \"jump\" in low: logging.warn(\"jump is not supported yet.\")\n",
      "WARNING:root:jump is not supported yet.\n",
      "/var/folders/yp/2knpzhtx0m196v_zk0jw8my80000gn/T/ipykernel_2808/1561739436.py:35: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  elif \"teleport\" in low: logging.warn(\"teleport is not supported yet.\")\n",
      "WARNING:root:teleport is not supported yet.\n",
      "WARNING:root:jump is not supported yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned: update 121 row(s), append 0 row(s).\n",
      "‚úÖ Updated 121 existing row(s).\n",
      "Done.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T10:13:09.669817Z",
     "start_time": "2025-09-11T10:13:09.668339Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "200f98a0aae8cbc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
